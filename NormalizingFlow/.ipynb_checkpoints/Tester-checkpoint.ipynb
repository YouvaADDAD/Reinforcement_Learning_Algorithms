{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ac4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import enum\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import seaborn as sns\n",
    "from torch.autograd import grad\n",
    "import scipy.stats as stats\n",
    "from utils import *\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c06d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowModules(FlowModule):\n",
    "    \"\"\"A container for a succession of flow modules\"\"\"\n",
    "    def __init__(self, *flows: FlowModule):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList(flows)\n",
    "\n",
    "    def apply(self, modules_iter, caller, x):\n",
    "        m, _ = x.shape\n",
    "        logdet = torch.zeros(m, device=x.device)\n",
    "        zs = [x]\n",
    "        for module in modules_iter:\n",
    "            x, _logdet = caller(module, x)\n",
    "            zs.append(x)\n",
    "            logdet += _logdet\n",
    "        return zs, logdet            \n",
    "\n",
    "    def modulenames(self, backward=False):\n",
    "        return [f\"L{ix} {module.__class__.__name__}\" for ix, module in enumerate(reversed(self.flows) if backward else self.flows)]\n",
    "\n",
    "    def f(self, x):\n",
    "        zs, logdet = self.apply(self.flows, lambda m, x: m.f(x), x)\n",
    "        return zs, logdet\n",
    "\n",
    "    def invf(self, y):\n",
    "        zs, logdet = self.apply(reversed(self.flows), lambda m, y: m.invf(y), y)\n",
    "        return zs, logdet\n",
    "\n",
    "\n",
    "class FlowModel(FlowModules):\n",
    "    \"\"\"Flow model = prior + flow modules\"\"\"\n",
    "    def __init__(self, prior, *flows: FlowModule):\n",
    "        super().__init__(*flows)\n",
    "        self.prior = prior\n",
    "\n",
    "    def invf(self, x):\n",
    "        # Just computes the prior\n",
    "        zs, logdet = super().invf(x)\n",
    "\n",
    "        logprob = self.prior.log_prob(zs[-1]) #z_0\n",
    "        print(logprob.shape)\n",
    "        return logprob, zs, logdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85107d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineFlow(FlowModule):\n",
    "    def __init__(self, in_features):\n",
    "        #in_features : la dimension des données\n",
    "        #On est en batchs\n",
    "        super().__init__()\n",
    "        self.s = nn.Parameter(torch.randn(in_features, requires_grad=True))#Broadcast x * s-> (batch, in_features)\n",
    "        self.t = nn.Parameter(torch.randn(in_features, requires_grad=True))#Broadcast x + s-> (batch, in_features)\n",
    "        \n",
    "    def f(self, x):\n",
    "        y = x * torch.exp(self.s) + self.t\n",
    "        logdet = torch.sum(self.s , dim = -1) #exp est toujours positive et log(exp(x)) = x\n",
    "        return y, logdet\n",
    "    \n",
    "    def invf(self, y):\n",
    "        x = (y - self.t) * torch.exp(- self.s) #f^{-1}(y)\n",
    "        logdet = - torch.sum(self.s, dim = -1)\n",
    "        assert self.f(x)[0].allclose(y, atol = 1e-02), 'f^{-1}(y) is not equal to x in AffineFlow'\n",
    "        return x, logdet\n",
    "    \n",
    "    def check(self, x):\n",
    "        return self.invf(self.f(x)[0])[0].allclose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d402dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On hérite de AffineFlow afin d'avoir le checker et réduire le code\n",
    "#Le broadcast sera toujours fait si (dim1, dim2) (op) (dim2) = (dim1, dim2) (op) (1, dim2)\n",
    "class ActNorm(AffineFlow):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__(in_features)\n",
    "        self.first_init = False\n",
    "    \n",
    "    def f(self, x):\n",
    "        if not self.first_init:\n",
    "            #z = (x - mean) / std \n",
    "            #torch.exp(self.s) = 1 / std\n",
    "            #self.t = - mean / std\n",
    "            #exp(- log(std)) = 1 / std pour plus de stabilité\n",
    "            #Nous obtenons bien z = x / std - mean / std = x - mean / std pour le premier batch\n",
    "            self.s.data.copy_(- torch.log(x.std(dim = 0) + 1e-8))\n",
    "            self.t.data.copy_(- x.mean(dim = 0) * torch.exp(self.s)) \n",
    "            self.first_init = True                \n",
    "        return super().f(x)\n",
    "    \n",
    "    def invf(self, y):\n",
    "        if not self.first_init:\n",
    "            #x = (y + mean / std) * std = y * std + mean\n",
    "            self.s.data.copy_(- torch.log(y.std(dim = 0) + 1e-8))\n",
    "            self.t.data.copy_(- y.mean(dim = 0) * torch.exp(self.s)) \n",
    "            self.first_init = True\n",
    "        return super().invf(y)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7318b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(FlowModule):\n",
    "    def __init__(self, in_features, hidden_dim = 64):\n",
    "        #Soit x la valeur actuelle de dimension 2×l\n",
    "        #2xl = in_features\n",
    "        #l = in_features/2\n",
    "        super().__init__()\n",
    "        assert in_features%2 == 0, 'Must be divisible by 2'\n",
    "        self.s = MLP(in_features // 2, in_features // 2, hidden_dim)\n",
    "        self.t = MLP(in_features // 2, in_features // 2, hidden_dim)\n",
    "    \n",
    "    def f(self, x):\n",
    "        #x : (batch, in_features)\n",
    "        assert x.shape[1]%2 ==0, 'Must be divisible by 2' \n",
    "        x_1, x_2 = torch.chunk(x, 2, dim = 1)\n",
    "        s = self.s(x_1)\n",
    "        t = self.t(x_1)\n",
    "        y_1 = x_1\n",
    "        y_2 = x_2 * torch.exp(s) + t\n",
    "        y = torch.cat((y_1, y_2), dim = 1)\n",
    "        logdet = torch.sum(s , dim = 1)\n",
    "        return y, logdet\n",
    "    \n",
    "    def invf(self, y):\n",
    "        assert y.shape[1]%2 ==0, 'Must be divisible by 2'\n",
    "        y_1, y_2 = torch.chunk(y, 2, dim = 1)\n",
    "        x_1 = y_1\n",
    "        s = self.s(x_1)\n",
    "        t = self.t(x_1)\n",
    "        x_2 = (y_2 - t) * torch.exp(- s)\n",
    "        x = torch.cat((x_1, x_2), dim = 1)\n",
    "        logdet =  - torch.sum(s, dim = 1)\n",
    "        assert self.f(x)[0].allclose(y, atol = 1e-05), 'f^{-1}(y) is not equal to x in AffineCouplingLayer'\n",
    "        return x, logdet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b02732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution1x1(FlowModule):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        W = torch.nn.init.orthogonal_(torch.randn(in_features, in_features)) #Matrice carrée\n",
    "        A_LU, pivots = W.lu()\n",
    "        P, W_L, W_U = torch.lu_unpack(A_LU, pivots)\n",
    "        self.P = P #Aucun changement\n",
    "        #Matrice triangulaires avec des diagonales à zéro pour L_prime et U_prime\n",
    "        self.L_prime = nn.Parameter(torch.tril(W_L, diagonal = -1)) \n",
    "        self.U_prime = nn.Parameter(torch.triu(W_U, diagonal = 1)) \n",
    "        self.S = nn.Parameter(torch.diag(torch.diag(W_U)))#Prendre la diagonal (in_features, in_features)\n",
    "        \n",
    "    def f(self, x):\n",
    "        W = (self.P @ (self.L_prime + torch.eye(self.in_features)) @ (self.U_prime + self.S))\n",
    "        y = x @ W\n",
    "        logdet = torch.sum(torch.log(torch.abs(self.S))) #sum(log(s)) lilianWen\n",
    "        return y, logdet\n",
    "    \n",
    "    def invf(self, y):\n",
    "        W = (self.P @ (self.L_prime + torch.eye(self.in_features)) @ (self.U_prime + self.S))\n",
    "        x = y @ torch.inverse(W)\n",
    "        logdet = -torch.sum(torch.log(torch.abs(self.S)))\n",
    "        assert self.f(x)[0].allclose(y, atol = 1e-05), 'f^{-1}(y) is not equal to x in Convolution1x1'\n",
    "        return x, logdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfb6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = []\n",
    "L = 10\n",
    "dim = 2\n",
    "hidden_dim = 64\n",
    "for _ in range(L):\n",
    "    modules.append(ActNorm(dim))\n",
    "    modules.append(AffineCouplingLayer(dim, hidden_dim = hidden_dim))\n",
    "    modules.append(Convolution1x1(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1914e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "batchsize = 64\n",
    "lr = 0.001\n",
    "nb_epochs = 100000\n",
    "mu = torch.zeros(dim)\n",
    "s = torch.ones(dim)\n",
    "prior = torch.distributions.independent.Independent(torch.distributions.normal.Normal(mu, s),1)\n",
    "model = FlowModel(prior, *modules)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4356529",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "f^{-1}(y) is not equal to x in AffineFlow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6fb49ef75eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mz_0_logprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_0_logprob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnegative_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9d66195946a0>\u001b[0m in \u001b[0;36minvf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Just computes the prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#z_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9d66195946a0>\u001b[0m in \u001b[0;36minvf\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9d66195946a0>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, modules_iter, caller, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_logdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlogdet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_logdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9d66195946a0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(m, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2ad04414db53>\u001b[0m in \u001b[0;36minvf\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ed7e2ce6c68d>\u001b[0m in \u001b[0;36minvf\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#f^{-1}(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f^{-1}(y) is not equal to x in AffineFlow'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: f^{-1}(y) is not equal to x in AffineFlow"
     ]
    }
   ],
   "source": [
    "for k in range(nb_epochs):\n",
    "        x, _ = datasets.make_circles(n_samples = batchsize, factor=0.5, noise=0.05, random_state=0)\n",
    "        x = torch.FloatTensor(x)\n",
    "        z_0_logprob, zs, logdet = model.invf(x)\n",
    "        logprob = z_0_logprob + logdet\n",
    "        negative_log_likelihood = - torch.mean(logprob)\n",
    "        model.zero_grad()\n",
    "        negative_log_likelihood.backward()\n",
    "        optimizer.step()\n",
    "        print(negative_log_likelihood.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python388jvsc74a57bd040d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
